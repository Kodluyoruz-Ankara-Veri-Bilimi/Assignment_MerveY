{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Class for Data Review\n",
    "\n",
    "Kodluyoruz Veri Bilimi 1. ödev Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import pylab\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro\n",
    "import scipy.stats as stats \n",
    "import statsmodels.stats.api as sms\n",
    "import numpy as np \n",
    "from scipy.stats import levene\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Information():\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        print(\"First 5 data: \\n\", data.head())\n",
    "        print(\"Last 5 data: \\n\", data.tail())\n",
    "        \n",
    "    def describe(self):\n",
    "        print(\"Data Describe: \\n\",data.describe().T)\n",
    "\n",
    "    def info():\n",
    "        print(\"Data Info: \",data.info())\n",
    "        print(\"Data Lenght: \", data.len())\n",
    "    \n",
    "    def columns(self):\n",
    "        print(\"Data Columns: \",data.columns)\n",
    "\n",
    "    def columnTypes():\n",
    "        print(\"Data Types: \", data.dtypes())\n",
    "        \n",
    "    def nullValues(self):\n",
    "        print(\"Null Values (any): \", self.data.isnull().values.any())\n",
    "        print(\"Null Values (sum): \", self.data.isnull().sum())\n",
    "        \n",
    "    def count(self):\n",
    "        print(\"Count: \",self.data.count())\n",
    "        \n",
    "    def num_data(self):\n",
    "        print(\"Numerical Data: \",self.data.select_dtypes(include=['float64','int64']))\n",
    "    \n",
    "    def cat_data(self):\n",
    "        print(\"Categorical Data: \",self.data.select_dtypes(include=[\"object\"])) \n",
    "        \n",
    "    def shape(self):\n",
    "        print(data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualization():\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "    def barPlot(self, columnName1, columnName2, columnName3 =None ):\n",
    "        sns.barplot(x= columnName1, y= columnName2, hue=columnName3, data=data)\n",
    "        plt.show()\n",
    "        \n",
    "    def boxPlot(self, columnName):       \n",
    "        sns.boxplot(data[columnName])\n",
    "        plt.show()       \n",
    "    \n",
    "    def countPlot(self,title):\n",
    "        sns.countplot(title, data=data)\n",
    "        \n",
    "    def corr(self):\n",
    "        print(\"Correlation of Data\", data.corr().head())\n",
    "        \n",
    "        f,ax = plt.subplots(figsize=(14,14))\n",
    "        sns.heatmap(data.corr(), annot=True, linewidths=.5, fmt='.1f', ax=ax)\n",
    "    \n",
    "    def factorPlot(self, columnName1,columnName2, columnName3= None):\n",
    "        sns.factorplot(columnName1,columnName2, hue=columnName3, data=data)\n",
    "        plt.show()\n",
    "        \n",
    "    def histogram(self, xTitle,yTitle, columnName, bins =None):\n",
    "        data[columnName].hist(bins = bins)\n",
    "        \n",
    "    def linePlot(self, columnName1):\n",
    "        fmri = sns.load_dataset(columnName1)\n",
    "        ax = sns.lineplot(x=xTitle, y=yTitle, data=fmri)\n",
    "        \n",
    "    def jointPlot(self, columnName1, columnName2):\n",
    "        sns.jointplot(x=columnName1, y=columnName2, data=data, kind=\"reg\")\n",
    "        \n",
    "    def pairPlot(self):\n",
    "        sns.pairplot(data, kind=\"reg\")\n",
    "        sns.pairplot(data, kind=\"scatter\")\n",
    "    \n",
    "    def probPlot(self, columnName):\n",
    "        stats.probplot(data[columnName], dist=\"norm\", plot=pylab)\n",
    "        pylab.show()\n",
    "    \n",
    "    def scatterPlot(self, xLabel, yLabel, columnName1, columnName2):\n",
    "        # 2 özellik arasındaki correlationı görmek için kullanılır\n",
    "        df.plot(kind='scatter', x= columnName1, y= columnName2, color='orange', alpha='0.4')\n",
    "        plt.xlabel(xLabel)\n",
    "        plt.ylabel(yLabel)\n",
    "        plt.title(xLabel +' - '+ yLabel)\n",
    "        \n",
    "    \n",
    "    def subPlot(self, x,y, columnName1, columnName2, xTitle, yTitle, yLabel):\n",
    "        \n",
    "        fig, ax = plt.subplots(x, y, figsize = (18, 8))\n",
    "        data[columnName1].value_counts().plot.bar(color = \"blue\", ax = ax[0])\n",
    "        ax[0].set_title(yTitle)\n",
    "        ax[0].set_ylabel(yLabel)\n",
    "        sns.countplot(columnName1, hue = columnName2, data = data, ax = ax[1])\n",
    "        ax[1].set_title(xTitle)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def violinPlot(self, x):\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        ax = sns.violinplot(x=\"day\", y=\"total_bill\", hue=\"smoker\", data=tips, palette=\"muted\")\n",
    "        \n",
    "    def QQPlot(self, columnName):\n",
    "        stats.probplot(columnName, dist=\"norm\", plot=pylab)\n",
    "        pylab.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "    def dropnaValueCount(columnName):\n",
    "        \n",
    "        #dropna=False Nan'larda dahil\n",
    "        data_ = data[columnName].value_counts(dropna=False)\n",
    "        print(data_)\n",
    "        \n",
    "    def concatenationVertical(columnName1, columnName2):\n",
    "        # Dikey birleştirme : axis=0\n",
    "        concat = pd.concat([columnName1,columnName2], axis=0, ignore_index=True)\n",
    "        print(\"Concatenating Data (vertical): \", concat)\n",
    "    \n",
    "    def concatenationHorizontal(columnName1, columnName2):\n",
    "        # Dikey birleştirme : axis=0\n",
    "        concat = pd.concat([columnName1,columnName2], axis=1)\n",
    "        print(\"Concatenating Data (horizontal):  \", concat)\n",
    "        \n",
    "    def dropna(columnName):\n",
    "        data[columnName].dropna(inplace=True)\n",
    "    \n",
    "    def fillna(columnName):\n",
    "        data[columnName].fillna(\"empty\",inplace=True)\n",
    "        \n",
    "    def dummy(columnName):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statistic():\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "    def shapiro(self, columnName):\n",
    "        \n",
    "        stats, p = shapiro(columnName)\n",
    "        if p > alpha:\n",
    "            print('Örneklem Normal (Gaussian) Dağılımdan gelmektedir (Fail to Reject H0)')\n",
    "        else:\n",
    "            print('Örneklem Normal (Gaussian) Dağılımdan gelmemektedir (reject H0)')\n",
    "    \n",
    "    def levene(self, columnName1, columnName2):\n",
    "        levene, p = levene(columnName1, columnName2)\n",
    "        print('Statistics=%.3f, p=%.3f' % (levene,p))\n",
    "        if p > alpha:\n",
    "            print('Varyanslar homojendir')\n",
    "        else:\n",
    "            print('Varyanslar homojen değildir')\n",
    "            \n",
    "    def wilcoxon(self, columnName1, columnName2):\n",
    "        stat, p = stats.wilcoxon(columnName1, columnName2)\n",
    "        print('Statistics=%.3f, p=%.3f' % (stat,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression():\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "    \n",
    "    def fitModel(self, X, Y):\n",
    "        lm = sm.OLS(y,X)\n",
    "        model = lm.fit()\n",
    "        return model\n",
    "    \n",
    "    def fitModelwithFormula(self):\n",
    "        lm = smf.ols(data)\n",
    "        model = lm.fit()\n",
    "        return model\n",
    "    \n",
    "    def modelSummary(self, model):\n",
    "        model.summary()\n",
    "    \n",
    "    def getParams(self, model):\n",
    "        model.params\n",
    "    \n",
    "    def getFittedValues(self, x,y):\n",
    "         print(\"Model Fitted Values: \",model.fittedvalues[x:y])\n",
    "        \n",
    "    def getModelIntercept(self,model):\n",
    "        print(\"Model Intercept: \",model.intercept_)\n",
    "    \n",
    "    def getModelCoef(self,model):\n",
    "        print(\"Model Coef: \",model.coef_)\n",
    "\n",
    "    def getModelScore(self,model, x,y):\n",
    "        print(\"Model Score: \",model.score(x,y))\n",
    "    \n",
    "    def meanSquaredError(self, y, model):\n",
    "        mse= mean_squared_error(y, model.fittedvalues)\n",
    "        print(\"Mean Squared Error: \", mse)\n",
    "        \n",
    "    def modelFittedValuesMean(self, model)\n",
    "        print(\" Fitted Values Mean\", mse/model.fittedvalues.mean())\n",
    "        \n",
    "    def rmse(self, mse):\n",
    "        rmse=np.sqrt(mse)\n",
    "        print(\"rmse: \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "    \n",
    "    def fit(self, loj, X,y):\n",
    "        loj_model = loj.fit(X,y)\n",
    "        return loj_model\n",
    "    \n",
    "    def modelIntercept(loj_model):\n",
    "        print(\"Model Intercept: \", loj_model.intercept_)\n",
    "    \n",
    "    def modelCoef(loj_model):\n",
    "        print(\"Model Coef: \", loj_model.coef_)\n",
    "    \n",
    "    def getProbability(X):\n",
    "        probability = loj_model.predict(X)[0:10]\n",
    "        return probability\n",
    "    \n",
    "    def predictProba(X):\n",
    "        print(loj_model.predict_proba(X)[0:10][:,0:2])\n",
    "    \n",
    "    def rocCurveArea(X):\n",
    "        logit_roc_auc = roc_auc_score(y, loj_model.predict(X))\n",
    "        print(\"Area : \",logit_roc_auc)\n",
    "        return logit_roc_auc\n",
    "    \n",
    "    def plotROC(logit_roc_auc):\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y, loj_model.predict_proba(X)[:,1])\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Oranı')\n",
    "        plt.ylabel('True Positive Oranı')\n",
    "        plt.title('ROC')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA():\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "    def cumSum(pca):\n",
    "        cumsum = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "        print(\"Cum. Sum: \", cumsum)\n",
    "        \n",
    "        features = range(pca.n_components_)\n",
    "        plt.bar(features, pca.explained_variance_ratio_, color=\"black\")\n",
    "        plt.xlabel('PCS features')\n",
    "        plt.ylabel('variance %')\n",
    "        plt.xticks(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DesicionTree():\n",
    "    # classification\n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "    def desicionTreeFunNonTuning(X_train, y_train, X_test, y_test):\n",
    "        cart = DecisionTreeClassifier()\n",
    "        cart_model = cart.fit(X_train,y_train)\n",
    "        print(\"\",skompile(cart_model.predict).to(\"python/code\"))\n",
    "        y_pred = cart_model.predict(X_test)\n",
    "        print(\"Accurarcy Score Before Tuning \", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    def plotTree(cart_model):\n",
    "        tree.plot_tree(cart_model);\n",
    "    \n",
    "    def karsilastirmaCart(cart_a,cart_b):\n",
    "        print(\"Cart before tuning: \",cart_b)\n",
    "        print(\"Cart after tuning:  \",cart_a)\n",
    "    \n",
    "        if(cart_a > cart_b):\n",
    "            print(\"İyileşme Oranı : \", cart_a - cart_b)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "# classification\n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "    \n",
    "    def RandomForestFyb(xtrain,ytrain, xtest, ytest ):\n",
    "        rf_model = RandomForestClassifier().fit(xtrain, ytrain)\n",
    "        y_pred = rf_model.predict(xtest)\n",
    "        print(\"Accurarcy before tuning\", accuracy_score(ytest, y_pred))\n",
    "    \n",
    "    def importanceFun(x):\n",
    "        Importance = pd.DataFrame({\"Importance\": x.feature_importances_*100},\n",
    "                          index = xtrain.columns)\n",
    "        Importance.sort_values(by=\"Importance\", axis=0, ascending=True).plot(kind=\"barh\")\n",
    "        plt.xlabel(\"Degisken Onem Duzeyleri\")\n",
    "        plt.show()\n",
    "        \n",
    "    def karsilastirmaRFR(rf_a,rf_b):\n",
    "        print(\"Random Forest before tuning: \",rf_b)\n",
    "        print(\"Random Forest after tuning:  \",rf_a)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "# classification\n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "    def NNfun(a,b,x_train_scaled,ytrain):\n",
    "        mlp_model = MLPClassifier(hidden_layer_sizes=(a,b)).fit(x_train_scaled, ytrain)\n",
    "        y_pred = mlp_model.predict(x_test_scaled)\n",
    "        print(\"Accurarcy before tuning\", accuracy_score(ytest, y_pred))\n",
    "        \n",
    "    def NNKarsilastirma(nn_a,nn_b):\n",
    "        print(\"NN before tuning: \",nn_b)\n",
    "        print(\"NN after tuning:  \",nn_a)\n",
    "    \n",
    "        if(cart_a > cart_b):\n",
    "            print(\"İyileşme Oranı : \", nn_a - nn_b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "    def svmFun(X_train, y_train, X_test, y_test):\n",
    "        svm_model = SVC(kernel = \"linear\").fit(X_train, y_train)\n",
    "        y_pred = svm_model.predict(X_test)\n",
    "        print(\"Accurarcy before tuning\", accuracy_score(ytest, y_pred))\n",
    "    \n",
    "    def classificationReport(y_test, y_pred):\n",
    "        print(\"Classification Report : \",classification_report(y_test, y_pred))\n",
    "        \n",
    "    def karsilastirmaSVM(svm_a,svm_b):\n",
    "        print(\"Cart before tuning: \",svm_b)\n",
    "        print(\"Cart after tuning:  \",svm_a)\n",
    "        \n",
    "        if(cart_a > cart_b):\n",
    "            print(\"İyileşme Oranı : \", svm_a - svm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "    def naiveBayesFun(X_train, y_train,X_test, y_test):\n",
    "        nb = GaussianNB()\n",
    "        nb_model = nb.fit(X_train, y_train)\n",
    "        print(\"Model Predict <first 10 data> :\",nb_model.predict(X_test)[0:10])\n",
    "        print(\"Model Predict with proba <first 10 data> :\", nb_model.predict_proba(X_test)[0:10])\n",
    "        \n",
    "        y_pred = nb_model.predict(X_test)\n",
    "        print(\"Accurarcy before tuning\", accuracy_score(ytest, y_pred))\n",
    "        print(\"Cross val score : \",cross_val_score(nb_model, X_test, y_test, cv=10).mean())\n",
    "    \n",
    "    \n",
    "    def multiNaiveBayesFun(X_train, y_train,X_test, y_test):\n",
    "        mnb = MultinomialNB()\n",
    "        mnb_model = mnb.fit(X_train, y_train)\n",
    "        y_pred = mnb_model.predict(X_test)\n",
    "        print(\"Accurarcy before tuning\", accuracy_score(ytest, y_pred))\n",
    "        print(\"Cross val score : \",cross_val_score(nb_model, X_test, y_test, cv=10).mean())\n",
    "        \n",
    "        \n",
    "    def bernoulliNaiveBayesFun(X_train, y_train,X_test, y_test):\n",
    "        bnb = BernoulliNB()\n",
    "        bnb_model = bnb.fit(X_train, y_train)\n",
    "        y_pred = mnb_model.predict(X_test)\n",
    "        print(\"Accurarcy before tuning\", accuracy_score(ytest, y_pred))\n",
    "        print(\"Cross val score : \",cross_val_score(nb_model, X_test, y_test, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boosting():\n",
    "    # classification\n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "    def gradientBoostingCFun(X_train, y_train,X_test, y_test):\n",
    "        GradientBoostingClassifier()\n",
    "        gbm_model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "        y_pred = gbm_model.predict(X_test)\n",
    "        print(\"Accurarcy before tuning\", accuracy_score(ytest, y_pred))\n",
    "        \n",
    "    def gradientBoostingParamsName(gbm_model):\n",
    "        print(\"Params Name for Gradient Boosting : \\n \", gbm_model.get_params())\n",
    "        \n",
    "    def lightGBMCFun(X_train, y_train,X_test, y_test):\n",
    "        lgbm_model = LGBMClassifier().fit(X_train, y_train)\n",
    "        y_pred = lgbm_model.predict(X_test)\n",
    "        print(\"Accurarcy before tuning\", accuracy_score(ytest, y_pred))\n",
    "    \n",
    "    def castBostCFun(X_train, y_train,X_test, y_test):\n",
    "        cat_model = CatBoostClassifier().fit(X_train, y_train)\n",
    "        y_pred = cat_model.predict(X_test)\n",
    "        print(\"Accurarcy before tuning\", accuracy_score(ytest, y_pred))\n",
    "    \n",
    "    def model_karsilastirma_classification(gb_B, gb_A, lgbm_B, lgbm_A, catB, catA):\n",
    "        print(\"Gradient Boosting <Before Tuning> Accurarcy : \", gb_B)\n",
    "        print(\"Gradient Boosting <After Tuning > Accurarcy : \", gb_A)\n",
    "        print(\"LIGHT GBM <Before Tuning> Accurarcy : \", lgbm_B)\n",
    "        print(\"LIGHT GBM <After Tuning > Accurarcy : \", lgbm_A)\n",
    "        print(\"Cat Boosting <Before Tuning> Accurarcy : \", catB)\n",
    "        print(\"Cat Boosting <After Tuning > Accurarcy : \", catA) \n",
    "        \n",
    "        #regression\n",
    "    def model_karsilastirma_regression(beforeTuning, afterTuning,lgbm_mseB,lgbm_mseA):\n",
    "        print(\"Gradient Boosting <Before Tuning> MSE : \", beforeTuning)\n",
    "        print(\"Gradient Boosting <After Tuning > MSE : \", afterTuning)\n",
    "        print(\"LIGHT GBM <Before Tuning> MSE : \", lgbm_mseB)\n",
    "        print(\"LIGHT GBM <After Tuning > MSE : \", lgbm_mseA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    # classification\n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "    \n",
    "    def knnFun(X_train, y_train,X_test, y_test):\n",
    "        knn = KNeighborsClassifier()\n",
    "        knn_model = knn.fit(X_train,y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        print(\"Accurarcy before tuning\", accuracy_score(ytest, y_pred))\n",
    "    \n",
    "    def classificationReport(y_test, y_pred):\n",
    "        print(\"Classification Report : \",classification_report(y_test, y_pred))\n",
    "    \n",
    "    def accurarcy_score_check(accscorebefore, accscoreafter):\n",
    "        print(\"Before Tuning score : \", accscorebefore )\n",
    "        print(\"After Tuning score :\", accscoreafter)\n",
    "    \n",
    "        if(accscoreafter > accscorebefore):\n",
    "            print(\"İyileşme oldu : \", accscoreafter-accscorebefore)\n",
    "    \n",
    "    #rmse\n",
    "    def rmse(knn_model):\n",
    "        RMSE = [] \n",
    "\n",
    "        for k in range(10):\n",
    "            k = k+1\n",
    "            knn_model = KNeighborsRegressor(n_neighbors = k).fit(X_train, y_train)\n",
    "            y_pred = knn_model.predict(X_train) \n",
    "            rmse = np.sqrt(mean_squared_error(y_train,y_pred)) \n",
    "            RMSE.append(rmse) \n",
    "            print(\"k =\" , k , \"için RMSE değeri: \", rmse)\n",
    "    \n",
    "    def rmse_rmsecv():\n",
    "        RMSE = [] \n",
    "        RMSE_CV = []\n",
    "        for k in range(10):\n",
    "            k = k+1\n",
    "            knn_model = KNeighborsRegressor(n_neighbors = k).fit(X_train, y_train)\n",
    "            y_pred = knn_model.predict(X_train) \n",
    "            rmse = np.sqrt(mean_squared_error(y_train,y_pred)) \n",
    "            rmse_cv = np.sqrt(-1*cross_val_score(knn_model, X_train, y_train, cv=10, \n",
    "                                         scoring = \"neg_mean_squared_error\").mean())\n",
    "            RMSE.append(rmse) \n",
    "            RMSE_CV.append(rmse_cv)\n",
    "            print(\"k =\" , k , \"için RMSE değeri: \", rmse, \"RMSE_CV değeri: \", rmse_cv )\n",
    "      \n",
    "    #regression\n",
    "    def knn_reg_kars(knn_reg_B,knn_reg_A):\n",
    "        print(\"KNN Before Tuning score MSE : \", knn_reg_B )\n",
    "        print(\"KNN After Tuning score MSE :\", knn_reg_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kmeans():\n",
    "    # classification\n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "    \n",
    "    def kMeansFun(data, n_clusters ):\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        k_fit = kmeans.fit(data)\n",
    "        print(\"**** \\n Cluster centers: \\n**** \\n \", k_fit.cluster_centers_)\n",
    "        print(\"**** \\n Labels: \\n**** \\n \", k_fit.labels_)\n",
    "        \n",
    "        kumeler = k_fit.labels_\n",
    "        merkezler = k_fit.cluster_centers_\n",
    "        \n",
    "    def optimumKumeSayisi(data,x,y):\n",
    "        kmeans = KMeans()\n",
    "        visualizer = KElbowVisualizer( kmeans, k=(x,y))\n",
    "        visualizer.fit(data)\n",
    "        visualizer.poof()\n",
    "    \n",
    "    def hiyerarsikKumeleme(data, type1, type2, type3):\n",
    "        # types : complete, average, centroid, ward, single etc.\n",
    "        hc_type1 = linkage(data, \"type1\")\n",
    "        hc_type2 = linkage(data, \"type2\")\n",
    "        hc_type3 = linkage(data, \"type3\")\n",
    "        \n",
    "\n",
    "    def dendogramPlot(X):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.title('Hiyerarşik Kümeleme - Dendogram')\n",
    "        plt.xlabel('Indexler')\n",
    "        plt.ylabel('Uzaklık')\n",
    "        dendrogram(hc_complete,leaf_font_size=10);\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
